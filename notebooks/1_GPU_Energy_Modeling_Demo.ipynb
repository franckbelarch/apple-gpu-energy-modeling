{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Energy Modeling Demo\n",
    "\n",
    "This notebook demonstrates the key components of the GPU energy modeling framework."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "import sys\nimport os\nsys.path.append('.')\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom src.benchmarks.compute_benchmarks import MatrixMultiplication, ConvolutionBenchmark\nfrom src.benchmarks.memory_benchmarks import MemoryCopy, RandomAccess\nfrom src.data_collection.collectors import SimulatedPowerCollector, PerformanceCounterCollector\nfrom src.modeling.energy_model import LinearEnergyModel\nfrom src.analysis.visualization import (\n    plot_power_over_time, \n    plot_component_breakdown,\n    plot_efficiency_comparison,\n    plot_model_feature_importance\n)\nfrom src.analysis.efficiency import (\n    calculate_energy_consumption,\n    analyze_energy_efficiency,\n    identify_efficiency_bottlenecks,\n    what_if_analysis\n)\n\n# Create data directories if they don't exist\nos.makedirs('data', exist_ok=True)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Running GPU Benchmarks\n",
    "\n",
    "First, let's run some benchmarks to generate workloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create benchmark instances\n",
    "matmul_benchmark = MatrixMultiplication()\n",
    "conv_benchmark = ConvolutionBenchmark()\n",
    "memcopy_benchmark = MemoryCopy()\n",
    "random_access_benchmark = RandomAccess()\n",
    "\n",
    "# Define benchmark parameters\n",
    "matmul_params = {\n",
    "    'matrix_size': 1024,\n",
    "    'dtype': np.float32\n",
    "}\n",
    "\n",
    "conv_params = {\n",
    "    'input_size': 224,\n",
    "    'kernel_size': 3,\n",
    "    'channels': 3,\n",
    "    'filters': 64\n",
    "}\n",
    "\n",
    "memcopy_params = {\n",
    "    'buffer_size_mb': 256,\n",
    "    'iterations': 5\n",
    "}\n",
    "\n",
    "random_access_params = {\n",
    "    'array_size_mb': 128,\n",
    "    'access_count': 1000000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the benchmarks\n",
    "print(\"Running Matrix Multiplication benchmark...\")\n",
    "matmul_results = matmul_benchmark.run(matmul_params)\n",
    "print(f\"Execution time: {matmul_results['mean_execution_time']:.4f} seconds\")\n",
    "\n",
    "print(\"\\nRunning Convolution benchmark...\")\n",
    "conv_results = conv_benchmark.run(conv_params)\n",
    "print(f\"Execution time: {conv_results['mean_execution_time']:.4f} seconds\")\n",
    "\n",
    "print(\"\\nRunning Memory Copy benchmark...\")\n",
    "memcopy_results = memcopy_benchmark.run(memcopy_params)\n",
    "print(f\"Execution time: {memcopy_results['mean_execution_time']:.4f} seconds\")\n",
    "\n",
    "print(\"\\nRunning Random Access benchmark...\")\n",
    "random_access_results = random_access_benchmark.run(random_access_params)\n",
    "print(f\"Execution time: {random_access_results['mean_execution_time']:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Collecting Power Data\n",
    "\n",
    "Next, let's collect simulated power data for these benchmarks."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Create power collector\npower_collector = SimulatedPowerCollector(sampling_interval=0.1)\ncounter_collector = PerformanceCounterCollector()\n\n# Collect power data for matrix multiplication\nprint(\"Collecting power data for Matrix Multiplication...\")\n# Create an activity pattern to simulate different phases\nduration = 5.0  # seconds\nnum_samples = int(duration / power_collector.sampling_interval)\n# Simulate a ramp-up, steady state, and cool-down pattern\nactivity_pattern = np.concatenate([\n    np.linspace(0.2, 0.9, num_samples // 4),  # Ramp up\n    np.linspace(0.9, 1.0, num_samples // 4),   # Peak\n    np.ones(num_samples // 4) * 0.95,          # Steady state\n    np.linspace(0.9, 0.2, num_samples // 4)    # Cool down\n])\n\nmatmul_power_data = power_collector.collect_for_duration(duration, activity_pattern)\nmatmul_power_df = pd.DataFrame(matmul_power_data)\n\n# Save data\nmatmul_power_df.to_csv('data/matmul_power.csv', index=False)\nprint(f\"Collected {len(matmul_power_data)} power samples\")\n\n# Collect sample performance counter data\ncounter_data = []\nfor i in range(len(matmul_power_data)):\n    counter_data.append(counter_collector.collect_counters())\n    \ncounter_df = pd.DataFrame([{\n    'timestamp': item['timestamp'],\n    **item['counters']\n} for item in counter_data])\n\ncounter_df.to_csv('data/matmul_counters.csv', index=False)\nprint(f\"Collected {len(counter_data)} counter samples\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualizing Power Data\n",
    "\n",
    "Let's visualize the power consumption data."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Plot power over time\ncomponent_cols = ['compute_power', 'memory_power', 'io_power']\nfig = plot_power_over_time(\n    matmul_power_df, \n    component_cols=component_cols,\n    title=\"Matrix Multiplication Power Consumption\",\n    save_path=\"data/matmul_power_over_time.png\"\n)\nplt.show()\n\n# Plot component breakdown\nfig = plot_component_breakdown(\n    matmul_power_df,\n    component_cols=component_cols,\n    title=\"Matrix Multiplication Power Breakdown\",\n    save_path=\"data/matmul_power_breakdown.png\"\n)\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Building an Energy Model\n",
    "\n",
    "Now, let's build a simple energy model using the collected data."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Prepare training data\n# For a real application, we would use actual performance counter data\n# Here we're using the simulated counter data\n\n# Merge counter data with power data based on closest timestamp\nmerged_df = pd.merge_asof(\n    counter_df.sort_values('timestamp'),\n    matmul_power_df[['timestamp', 'total_power']].sort_values('timestamp'),\n    on='timestamp',\n    direction='nearest'  # Use nearest match to ensure better correspondence\n)\n\nprint(f\"Shape of merged data: {merged_df.shape}\")\n\n# Check for data quality\nfor col in ['sm_activity', 'memory_utilization', 'cache_hit_rate', 'memory_throughput', 'total_power']:\n    print(f\"{col}: mean={merged_df[col].mean():.2f}, std={merged_df[col].std():.2f}, range={merged_df[col].max() - merged_df[col].min():.2f}\")\n\n# Create correlation matrix\ncorrelation = merged_df[['sm_activity', 'memory_utilization', 'cache_hit_rate', \n                        'instructions_executed', 'memory_throughput', 'total_power']].corr()\n                        \nprint(\"\\nCorrelation with total_power:\")\nfor col in ['sm_activity', 'memory_utilization', 'cache_hit_rate', 'instructions_executed', 'memory_throughput']:\n    print(f\"  {col}: {correlation.loc[col, 'total_power']:.4f}\")\n\n# Select features and target\nfeature_cols = [\n    'sm_activity', 'memory_utilization', 'cache_hit_rate', \n    'instructions_executed', 'memory_throughput'\n]\nX = merged_df[feature_cols].values\ny = merged_df['total_power'].values\n\n# Add small amount of noise to ensure model doesn't have perfect fit\n# This simulates real-world measurement noise\nnp.random.seed(42)  # For reproducibility\nX_noisy = X + np.random.normal(0, 0.05 * np.mean(X, axis=0), size=X.shape)\ny_noisy = y + np.random.normal(0, 0.05 * np.mean(y), size=y.shape)\n\n# Create scatter plots to verify relationships\nplt.figure(figsize=(15, 10))\nfor i, col in enumerate(feature_cols):\n    plt.subplot(2, 3, i+1)\n    plt.scatter(X_noisy[:, i], y_noisy, alpha=0.5)\n    plt.title(f'{col} vs Power')\n    plt.xlabel(col)\n    plt.ylabel('total_power')\n\nplt.tight_layout()\nplt.show()\n\n# Train the model\nmodel = LinearEnergyModel(model_name=\"gpu_power_model\", alpha=0.1)\ntraining_results = model.train(X_noisy, y_noisy)\n\nprint(\"\\nModel Training Results:\")\nprint(f\"Training RMSE: {training_results['train_metrics']['rmse']:.4f}\")\nprint(f\"Validation RMSE: {training_results['val_metrics']['rmse']:.4f}\")\nprint(f\"Validation RÂ²: {training_results['val_metrics']['r2']:.4f}\")\n\n# Print model coefficients\nprint(\"\\nModel Coefficients:\")\nfor feature, coef in model.feature_importance.items():\n    feature_idx = int(feature.split('_')[1])\n    feature_name = feature_cols[feature_idx]\n    print(f\"  {feature_name}: {coef:.4f}\")"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Visualize feature importance from the noisy model (which should have proper values)\nfeature_importance_dict = {}\nfor feature, coef in model.feature_importance.items():\n    feature_idx = int(feature.split('_')[1])\n    feature_name = feature_cols[feature_idx]\n    feature_importance_dict[feature_name] = coef\n\nfig = plot_model_feature_importance(\n    feature_importance_dict,\n    title=\"GPU Power Model Feature Importance\",\n    save_path=\"data/model_feature_importance.png\"\n)\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Energy Efficiency Analysis\n",
    "\n",
    "Let's analyze the energy efficiency of the benchmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate energy consumption\n",
    "total_energy = calculate_energy_consumption(matmul_power_df)\n",
    "print(f\"Total energy consumption: {total_energy:.2f} joules\")\n",
    "\n",
    "# Prepare benchmark results with additional information\n",
    "matmul_metrics = {\n",
    "    'operations': matmul_results['raw_results'][0]['operations'],\n",
    "    'execution_time': matmul_results['mean_execution_time']\n",
    "}\n",
    "\n",
    "# Analyze efficiency\n",
    "efficiency_metrics = analyze_energy_efficiency(matmul_metrics, matmul_power_df)\n",
    "\n",
    "print(\"\\nEfficiency Metrics:\")\n",
    "for metric, value in efficiency_metrics.items():\n",
    "    print(f\"{metric}: {value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify potential bottlenecks\n",
    "bottlenecks = identify_efficiency_bottlenecks(matmul_power_df, counter_df)\n",
    "\n",
    "print(\"Efficiency Bottleneck Analysis:\")\n",
    "for bottleneck, details in bottlenecks.items():\n",
    "    print(f\"\\n{bottleneck}:\")\n",
    "    if isinstance(details, dict):\n",
    "        for key, value in details.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "    else:\n",
    "        print(f\"  {details}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. What-If Analysis\n",
    "\n",
    "Let's perform some what-if analysis to identify optimization opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define baseline and scenario adjustments\n",
    "baseline_features = np.mean(X, axis=0)  # Average of all observations\n",
    "\n",
    "# Define scenarios to analyze\n",
    "scenarios = {\n",
    "    'Improved_Cache_Hits': {\n",
    "        'cache_hit_rate': (1.25, 0)  # 25% increase in cache hit rate\n",
    "    },\n",
    "    'Reduced_Memory_Bandwidth': {\n",
    "        'memory_throughput': (0.8, 0)  # 20% decrease in memory bandwidth\n",
    "    },\n",
    "    'Optimized_Compute': {\n",
    "        'instructions_executed': (0.7, 0),  # 30% fewer instructions\n",
    "        'sm_activity': (0.9, 0)  # 10% decrease in SM activity\n",
    "    },\n",
    "    'Combined_Optimizations': {\n",
    "        'cache_hit_rate': (1.2, 0),  # 20% increase in cache hits\n",
    "        'instructions_executed': (0.8, 0),  # 20% fewer instructions\n",
    "        'memory_throughput': (0.9, 0)  # 10% less memory bandwidth\n",
    "    }\n",
    "}\n",
    "\n",
    "# Run what-if analysis\n",
    "scenario_results = what_if_analysis(model, baseline_features, scenarios, feature_cols)\n",
    "\n",
    "# Print results\n",
    "print(f\"Baseline Power: {scenario_results['baseline_power']:.2f} W\")\n",
    "print(\"\\nScenario Analysis:\")\n",
    "\n",
    "for scenario, results in scenario_results['scenarios'].items():\n",
    "    print(f\"\\n{scenario}:\")\n",
    "    print(f\"  Predicted Power: {results['power']:.2f} W\")\n",
    "    print(f\"  Change: {results['absolute_change']:.2f} W ({results['percent_change']:.2f}%)\")\n",
    "    \n",
    "    print(\"  Adjusted Features:\")\n",
    "    for feature, value in results['adjusted_features'].items():\n",
    "        print(f\"    {feature}: {value:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusion and Next Steps\n",
    "\n",
    "Based on our analysis, we can identify the following key insights and opportunities for optimization:\n",
    "\n",
    "1. **Power Breakdown**: The primary power consumers in our benchmark are...\n",
    "2. **Key Performance Counters**: The most significant predictors of power consumption are...\n",
    "3. **Optimization Opportunities**: The most promising optimization approaches are...\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Collect real hardware measurements for more accurate modeling\n",
    "- Extend the benchmark suite with more diverse workloads\n",
    "- Implement more sophisticated modeling approaches (ML-based models)\n",
    "- Develop automated optimization recommendation system\n",
    "- Create comprehensive visualization dashboard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}